---
import BaseLayout from "@layouts/BaseLayout.astro";
---
<style>
    ol {
        list-style: decimal; /* Ensure default numbering */
        padding-left: 40px; /* Add space from the left */
    }
</style>
<BaseLayout title="ASR Indic Report">
  <div class="project-report">
  <div style="text-align: center;">
    <h1> <b>Automated Speech Recognition for Indic Language </b></h1>
    <p>
      <!-- Project description and detailed report goes here.-->
    </p>
    <a href="https://madhavlab.github.io/" style="text-decoration: underline;"><h2>Madhav Labs</h2></a>
    </div>
    <h2><u>Professor in charge:</u> Prof. Vipul Arora<br>
    <u>Timeline:</u> February 2023-July 2023 </h2>
    <br>
    <p>
    <h2><b>Brief Description</b></h2>
    The project aimed at building offline Automated Speech Recognition(ASR) models for Indic Languages using Machine Learning. The project has 2 parts,
    with the first part focussing on providing offline Hindi ASR for a news channel. The second part of the project was focussed on
     participating in MADASR competition, conducted by ASRU. This competition focussed on building ASR models fopr low resource indic 
     languages, namely Bhojpuri and Bengali. We achieved global rank 2 in two tracks of the competition: Bengali Track 2(Metric: Charecter Error Rate(CER)) and Bhojpuri 
     Track 2(metric: Word Error Rate(WER)).
     <h2><b>Technical Details</b></h2>
     
     <ol>
        <li><u>Hindi ASR:</u> <br>
        The aim of the project was to build a Hindi ASR model for offline captioning for a Hindi 
        news company. There are a lot of publically available datasets for English Speech recognition 
        included LIBRI speech, but there is lesser data available for hindi language for developing high
        high level transformer and conformer models which require high amount of labelled data. 
        <br>
        To tackle with the sparse Hindi ASR data, we had a transcription team, transcribing hours of Hindi News data. 
        We built a conformer model on our ready-made dataset. This data was combined with the publically available
        hindi ASR data: All India Radio, Door darshan, Akash Wani. This model was further equipped with Beam search to 
        improve performance of the model. Using cross validation, the beam size of 1500 was used. To navigate the issues corresponding to errors in transcribing data
        the model was further equipped with a statistical language model: 6 gram KenLM model, trained on scrapped hindi texts.
        
         
        <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hindi ASR Table</title>
    <style>
        table {
            border: 1px solid black;
            border-collapse: collapse;
            width: 50%;
            margin-left: 200px; /* Left margin only */
            margin-top: 20px; /* Adds space above the table */
            margin-bottom: 20px; /* Adds space below the table */
        }
        th, td {
            border: 1px solid black;
            padding: 8px;
        }
        th {
            text-align: center; /* Center-align the headers */
        }
        td {
            text-align: center; /* Center-align data */
        }
        td:first-child {
            text-align: left; /* Left-align the first column */
        }
    </style>
</head>
<body>
  
    <table>
        <thead>
            <tr>
                <th>Hindi ASR Model Details</th>
                <th>WER</th>
                <th>CER</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Greedy Decoder</td>
                <td>26%</td>
                <td>13%</td>
            </tr>
            <tr>
                <td>Greedy Decoder + Beam Search</td>
                <td>16%</td>
                <td>10%</td>
            </tr>
            <tr>
                <td>Greedy Decoder + Beam Search + LM</td>
                <td>11%</td>
                <td>7%</td>
            </tr>
        </tbody>
    </table>


</body>
Once the conformer model was successfully integrated with the beam search and LM, the model was
 adapted for the long-form audios using CTC decoder based chunking.
 <body><br>
<br><u>Long-form Hindi audios with noise: </u>

    <table>
        <thead>
            <tr>
                <th>Hindi ASR Model Details</th>
                <th>WER</th>
                <th>CER</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Greedy Decoder</td>
                <td>33%</td>
                <td>18%</td>
            </tr>
            <tr>
                <td>Greedy Decoder + Beam Search</td>
                <td>30%</td>
                <td>16%</td>
            </tr>
            <tr>
                <td>Greedy Decoder + Beam Search + LM</td>
                <td>27%</td>
                <td>15%</td>
            </tr>
        </tbody>
    </table>
<br><u>Long-form Hindi audios without noise: </u>
    <table>
        <thead>
            <tr>
                <th>Hindi ASR Model Details</th>
                <th>WER</th>
                <th>CER</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Greedy Decoder</td>
                <td>18%</td>
                <td>14%</td>
            </tr>
            <tr>
                <td>Greedy Decoder + Beam Search</td>
                <td>11%</td>
                <td>8%</td>
            </tr>
            <tr>
                <td>Greedy Decoder + Beam Search + LM</td>
                <td>7%</td>
                <td>7%</td>
            </tr>
        </tbody>
    </table>
</body>
        
        </li>

        <li><u>Model Adaptation for ASR(MADASR) Competition, IEEE Automatic Speech Recognition and Understanding(ASRU), 2023:</u>
        <br>
        The problem statement for the challenge was about making offline ASR models for low resource indic languages
        namely Bengali and Bhojpuri. The competition provided 850 hours of labelled data fo each language. The 
        competition had 4 tracks, each limiting on the amount of labelled data that can be used. 
        <br>
        We tried out 2 approaches to tackle the problem:
       <ol style="list-style-type: upper-alpha;">
    <li><u>Fine-tuning Wave2Vec model</li><br>
    There exists no wave2vec model in these languages, but a lot of research has been conducted in ASR using 
    these models for English language. To leverage the existing research we used the novel approach of 
    transliterating these language texts in english. This allowed us to leverage the existing english based 
    Wave2vec models for Bengali and Bhojpuri Languages. AI4Bharat library was used for transliterating the text.

    <li><u>Training Conformer models</u></li>
    A conformer model was setup along with Beam Search and KenLM using the given data.
    <table border="1" style="border-collapse: collapse; text-align: center; margin-left: 20px; margin-top: 20px; margin-bottom: 20px; width: 80%;">

    <thead>
        <tr>
            <th style="padding: 10px;">Bhojpuri Conformer ASR Track 2</th>
            <th style="padding: 10px;">WER</th>
            <th style="padding: 10px;">CER</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="padding: 10px;">Greedy Decoder</td>
            <td style="padding: 10px;">26%</td>
            <td style="padding: 10px;">10%</td>
        </tr>
        <tr>
            <td style="padding: 10px;">Greedy Decoder + Beam Search</td>
            <td style="padding: 10px;">26%</td>
            <td style="padding: 10px;">10%</td>
        </tr>
        <tr>
            <td style="padding: 10px;">Greedy Decoder + Beam Search + LM</td>
            <td style="padding: 10px;">21%</td>
            <td style="padding: 10px;">9%</td>
        </tr>
    </tbody>
</table>
<table border="1" style="border-collapse: collapse; text-align: center; margin-left: 20px; margin-top: 20px; margin-bottom: 20px; width: 80%;">
    
    <thead>
        <tr>
            <th style="padding: 10px;">Bengali Conformer ASR Track 2</th>
            <th style="padding: 10px;">WER</th>
            <th style="padding: 10px;">CER</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="padding: 10px;">Greedy Decoder</td>
            <td style="padding: 10px;">27%</td>
            <td style="padding: 10px;">8%</td>
        </tr>
        <tr>
            <td style="padding: 10px;">Greedy Decoder + Beam Search</td>
            <td style="padding: 10px;">26%</td>
            <td style="padding: 10px;">9%</td>
        </tr>
        <tr>
            <td style="padding: 10px;">Greedy Decoder + Beam Search + LM</td>
            <td style="padding: 10px;">25%</td>
            <td style="padding: 10px;">10%</td>
        </tr>
    </tbody>
</table>
The results were further improved by implementing a SOTA domain adaptation model: DUST(Dropout-based uncertainty-driven self-training). 
This method leveraged the predicted transcriptions with high confidence score to increase the size of train 
data and further diversify the training data.  
<table border="1" style="border-collapse: collapse; text-align: center; margin-left: 20px; margin-top: 20px; margin-bottom: 20px; width: 80%;">
    <thead>
        <tr>
            <th style="padding: 10px;">Bhojpuri DUST Conformer Track 2</th>
            <th style="padding: 10px;">WER</th>
            <th style="padding: 10px;">CER</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="padding: 10px;">Greedy Decoder + Beam Search + LM</td>
            <td style="padding: 10px;">21%</td>
            <td style="padding: 10px;">8%</td>
        </tr>
    </tbody>
</table>
<table border="1" style="border-collapse: collapse; text-align: center; margin-left: 20px; margin-top: 20px; margin-bottom: 20px; width: 80%;">
    <thead>
        <tr>
            <th style="padding: 10px;">Bengali DUST Conformer Track 2</th>
            <th style="padding: 10px;">WER</th>
            <th style="padding: 10px;">CER</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="padding: 10px;">Greedy Decoder + Beam Search + LM</td>
            <td style="padding: 10px;">26%</td>
            <td style="padding: 10px;">10%</td>
        </tr>
    </tbody>
</table>

</ol>


</li>
    </ol>
    </p>
  </div>
</BaseLayout>
